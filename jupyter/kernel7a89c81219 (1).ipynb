{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_2d(a, window):\n",
    "    nrow, ncol = a.shape\n",
    "    shape = nrow - window, window, ncol\n",
    "    strides = a.strides[0], a.strides[0], a.strides[-1]\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ea28b224b04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c9b6c84b6890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwindows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrolling_window_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "windows = rolling_window_2d(dataset.values, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 300.  ],\n",
       "       [    nan],\n",
       "       [    nan],\n",
       "       ...,\n",
       "       [4006.01],\n",
       "       [4005.5 ],\n",
       "       [4005.99]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(df[\"Close\"].values, df[\"Close\"].values.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rolling_window(df[\"Close\"].values[-500:], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_1d(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from datetime import datetime \n",
    "    sc = MinMaxScaler()\n",
    "    sc_for_close = MinMaxScaler()\n",
    "    window = 20\n",
    "    how = {\n",
    "        \"Open\": 'first',\n",
    "        \"High\": 'max',\n",
    "        \"Low\": \"min\",\n",
    "        \"Close\": \"last\",\n",
    "        \"Volume_(Currency)\": 'sum'\n",
    "    }\n",
    "    df.loc[:, \"datetime\"] = pd.to_datetime(df[\"Timestamp\"], unit='s')\n",
    "    df = df.set_index(\"datetime\")\n",
    "    df = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume_(Currency)\"]]\n",
    "    df = df.resample(\"60min\", how=how)\n",
    "    df = df[datetime(2017, 7, 1):]\n",
    "    df = df.bfill()\n",
    "    diff = df.diff()\n",
    "    while True:\n",
    "        dataset = sc.fit_transform(np.reshape(df[\"Close\"].values, df[\"Close\"].values.shape + (1, )))\n",
    "        dataset = np.reshape(dataset, df[\"Close\"].values.shape)\n",
    "        dataset\n",
    "        x_window = rolling_window(dataset, window)\n",
    "        print(x_window.shape)\n",
    "        x_window = np.reshape(x_window, x_window.shape + (1, ))\n",
    "        x = x_window[:-1]\n",
    "        y = dataset[window:]\n",
    "        # y = dataset\n",
    "        \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, shuffle=False)\n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test, sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_1d(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from datetime import datetime \n",
    "    sc = MinMaxScaler()\n",
    "    sc_for_close = MinMaxScaler()\n",
    "    window = 20\n",
    "    how = {\n",
    "        \"Open\": 'first',\n",
    "        \"High\": 'max',\n",
    "        \"Low\": \"min\",\n",
    "        \"Close\": \"last\",\n",
    "        \"Volume_(Currency)\": 'um'\n",
    "    }\n",
    "    df.loc[:, \"datetime\"] = pd.to_datetime(df[\"Timestamp\"], unit='s')\n",
    "    df = df.set_index(\"datetime\")\n",
    "    df = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume_(Currency)\"]]\n",
    "    df = df.resample(\"60min\", how=how)\n",
    "    df = df[datetime(2017, 7, 1):]\n",
    "    df = df.bfill()\n",
    "    dataset = sc.fit_transform(np.reshape(df[\"Close\"].values, df[\"Close\"].values.shape + (1, )))\n",
    "    dataset = np.reshape(dataset, df[\"Close\"].values.shape)\n",
    "    dataset\n",
    "    x_window = rolling_window(dataset, window)\n",
    "    print(x_window.shape)\n",
    "    x_window = np.reshape(x_window, x_window.shape + (1, ))\n",
    "    x = x_window[:-1]\n",
    "    # y = dataset[window:]\n",
    "    y = dataset\n",
    "    print(x, y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, shuffle=False)\n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test, sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from datetime import datetime \n",
    "    sc = MinMaxScaler()\n",
    "    sc_for_close = MinMaxScaler()\n",
    "    window = 100\n",
    "    how = {\n",
    "        \"Open\": 'first',\n",
    "        \"High\": 'max',\n",
    "        \"Low\": \"min\",\n",
    "        \"Close\": \"last\",\n",
    "        \"Volume_(Currency)\": 'sum'\n",
    "    }\n",
    "    df.loc[:, \"datetime\"] = pd.to_datetime(df[\"Timestamp\"], unit='s')\n",
    "    df = df.set_index(\"datetime\")\n",
    "    df = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume_(Currency)\"]]\n",
    "    df = df.resample(\"60min\", how=how)\n",
    "    df = df[datetime(2017, 7, 1):]\n",
    "    df = df.bfill()\n",
    "    # dataset = sc.fit_transform(df.values)\n",
    "    # sc_for_close.fit(np.reshape(df[\"Close\"].values, df[\"Close\"].values.shape + (1, )))\n",
    "    x_window = rolling_window_2d(dataset, window)\n",
    "    x = x_window[:]\n",
    "    y = dataset[window:, [3]]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, shuffle=False)\n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test, sc_for_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataset_1d = preprocessing_1d(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test, scfc = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test, scfc = dataset_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense, InputLayer\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(5, name=\"lstm\", input_shape=(100, 5)),\n",
    "    Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "mc = ModelCheckpoint(\"super_model_lstm_20.h5\", verbose=1, monitor='val_loss', save_weights_only=False, save_best_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=500, callbacks=[es, mc], batch_size=128, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "super_model = load_model(\"super_model_lstm_20.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test\n",
    "predicted_BTC_price = super_model.predict(x_test)\n",
    "predicted_BTC_price_real = scfc.inverse_transform(predicted_BTC_price)\n",
    "y_test_real = scfc.inverse_transform(np.reshape(y_test, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_real_plot = y_test_real[-1000:-950]\n",
    "predicted_BTC_price_real_plot = predicted_BTC_price_real[-1000:-950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(25,15), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = plt.gca()\n",
    "plt.plot(y_test_real_plot, color = 'red', label = 'Real BTC Price')\n",
    "plt.plot(predicted_BTC_price_real_plot, color = 'blue', label = 'Predicted BTC Price')\n",
    "\n",
    "plt.title('BTC Price Prediction', fontsize=40)\n",
    "plt.xlabel('Time', fontsize=40)\n",
    "plt.ylabel('BTC Price(USD)', fontsize=40)\n",
    "plt.legend(loc=2, prop={'size': 25})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
